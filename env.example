# Council of LLM Models - Environment Variables Example
# Copy this file to .env and fill in your API keys

# API Keys (Get free keys from respective providers)
# Groq: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Hugging Face: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Google Gemini: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# Together AI: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=your_together_api_key_here

# Cohere: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=your_cohere_api_key_here

# Configuration Options (Optional - defaults are in config.py)
# Number of discussion rounds (default: 2)
# COUNCIL_DISCUSSION_ROUNDS=2

# Voting mode (default: majority)
# COUNCIL_VOTING_MODE=majority

# Ollama base URL (default: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# Model timeout in seconds (default: 60)
# MODEL_TIMEOUT=60

# Maximum retry attempts (default: 3)
# MAX_RETRIES=3

